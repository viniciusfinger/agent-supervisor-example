# Reducing LLM hallucinations with Agent Supervisor Architecture

LLMs hallucinate all the time. It's not a question of IF it will happen, but WHEN it will happen and if your system will be prepared to handle it.

You can read the full article on my Medium.