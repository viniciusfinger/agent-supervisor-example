# Reducing LLM hallucinations with Agent Supervisor Architecture

LLMs hallucinate all the time. It's not a question of IF it will happen, but WHEN it will happen and if your system will be prepared to handle it.

You can read the full article on my Medium: https://medium.com/@fingervinicius/reducing-llm-hallucinations-with-agent-supervisor-architecture-569f572d0da1
